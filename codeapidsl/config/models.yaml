generators:
  codellama:
    endpoint: "http://localhost:8000/v1/completions"
    model_name: "codellama/CodeLlama-13b-Instruct-hf"
    max_tokens: 1024
    temperature: 0.7
  
  starcoder:
    endpoint: "http://localhost:8001/v1/completions"
    model_name: "bigcode/starcoder"
    max_tokens: 2048
    temperature: 0.6

validation:
  syntax_check: true
  compilation_check: true
  style_check: true
  unit_test_generation: true

output:
  default_format: "jsonl"
  include_metadata: true
  validation_details: true