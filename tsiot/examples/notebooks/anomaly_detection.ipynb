{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# TSIOT Anomaly Detection Example\n",
    "\n",
    "This notebook demonstrates anomaly detection techniques using TSIOT-generated synthetic time series data.\n",
    "\n",
    "## Techniques Covered:\n",
    "1. Statistical anomaly detection (Z-score, IQR)\n",
    "2. Isolation Forest\n",
    "3. Local Outlier Factor (LOF)\n",
    "4. Autoencoder-based detection\n",
    "5. LSTM-based anomaly detection"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Install required packages\n",
    "!pip install requests pandas numpy matplotlib seaborn scikit-learn tensorflow plotly"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import requests\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "from sklearn.ensemble import IsolationForest\n",
    "from sklearn.neighbors import LocalOutlierFactor\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "import tensorflow as tf\n",
    "from tensorflow.keras.models import Model\n",
    "from tensorflow.keras.layers import Input, LSTM, Dense, RepeatVector, TimeDistributed\n",
    "import warnings\n",
    "warnings.filterwarnings('ignore')\n",
    "\n",
    "plt.style.use('seaborn-v0_8')\n",
    "plt.rcParams['figure.figsize'] = (15, 10)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 1. Generate Synthetic Data with Anomalies"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# TSIOT API configuration\n",
    "TSIOT_BASE_URL = \"http://localhost:8080\"\n",
    "API_KEY = \"your-api-key-here\"\n",
    "\n",
    "headers = {\n",
    "    \"Content-Type\": \"application/json\",\n",
    "    \"Authorization\": f\"Bearer {API_KEY}\"\n",
    "}\n",
    "\n",
    "def generate_normal_series():\n",
    "    \"\"\"Generate normal time series data.\"\"\"\n",
    "    data = {\n",
    "        \"type\": \"lstm\",\n",
    "        \"length\": 1000,\n",
    "        \"parameters\": {\n",
    "            \"trend\": 0.05,\n",
    "            \"seasonality\": 24,\n",
    "            \"noise\": 0.1\n",
    "        }\n",
    "    }\n",
    "    \n",
    "    response = requests.post(f\"{TSIOT_BASE_URL}/api/v1/generate\", json=data, headers=headers)\n",
    "    return response.json() if response.status_code == 200 else None\n",
    "\n",
    "def inject_anomalies(values, anomaly_rate=0.05):\n",
    "    \"\"\"Inject synthetic anomalies into time series.\"\"\"\n",
    "    anomalous_values = values.copy()\n",
    "    n_anomalies = int(len(values) * anomaly_rate)\n",
    "    anomaly_indices = np.random.choice(len(values), n_anomalies, replace=False)\n",
    "    \n",
    "    for idx in anomaly_indices:\n",
    "        # Create different types of anomalies\n",
    "        anomaly_type = np.random.choice(['spike', 'dip', 'shift'])\n",
    "        \n",
    "        if anomaly_type == 'spike':\n",
    "            anomalous_values[idx] *= np.random.uniform(3, 5)\n",
    "        elif anomaly_type == 'dip':\n",
    "            anomalous_values[idx] *= np.random.uniform(0.1, 0.3)\n",
    "        elif anomaly_type == 'shift':\n",
    "            shift_length = min(20, len(values) - idx)\n",
    "            shift_value = np.random.uniform(-2, 2) * np.std(values)\n",
    "            anomalous_values[idx:idx+shift_length] += shift_value\n",
    "    \n",
    "    return anomalous_values, anomaly_indices\n",
    "\n",
    "# Generate data\n",
    "normal_data = generate_normal_series()\n",
    "if normal_data:\n",
    "    normal_values = np.array(normal_data['values'])\n",
    "    anomalous_values, true_anomaly_indices = inject_anomalies(normal_values)\n",
    "    \n",
    "    # Create DataFrame\n",
    "    timestamps = pd.date_range(start='2023-01-01', periods=len(normal_values), freq='H')\n",
    "    df = pd.DataFrame({\n",
    "        'timestamp': timestamps,\n",
    "        'normal': normal_values,\n",
    "        'anomalous': anomalous_values,\n",
    "        'is_anomaly': False\n",
    "    })\n",
    "    df.loc[true_anomaly_indices, 'is_anomaly'] = True\n",
    "    df.set_index('timestamp', inplace=True)\n",
    "    \n",
    "    print(f\"✅ Generated {len(df)} data points with {len(true_anomaly_indices)} anomalies\")\n",
    "else:\n",
    "    print(\"❌ Failed to generate data\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Visualize normal vs anomalous data\n",
    "fig, axes = plt.subplots(2, 1, figsize=(15, 10))\n",
    "\n",
    "# Normal data\n",
    "axes[0].plot(df.index, df['normal'], color='blue', alpha=0.7, label='Normal Data')\n",
    "axes[0].set_title('Normal Time Series')\n",
    "axes[0].set_ylabel('Value')\n",
    "axes[0].grid(True, alpha=0.3)\n",
    "axes[0].legend()\n",
    "\n",
    "# Anomalous data with anomalies highlighted\n",
    "axes[1].plot(df.index, df['anomalous'], color='blue', alpha=0.7, label='Time Series')\n",
    "anomaly_points = df[df['is_anomaly']]\n",
    "axes[1].scatter(anomaly_points.index, anomaly_points['anomalous'], \n",
    "               color='red', s=50, alpha=0.8, label=f'Anomalies ({len(anomaly_points)})')\n",
    "axes[1].set_title('Time Series with Injected Anomalies')\n",
    "axes[1].set_ylabel('Value')\n",
    "axes[1].set_xlabel('Time')\n",
    "axes[1].grid(True, alpha=0.3)\n",
    "axes[1].legend()\n",
    "\n",
    "plt.tight_layout()\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 2. Statistical Anomaly Detection"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def detect_anomalies_zscore(values, threshold=3):\n",
    "    \"\"\"Detect anomalies using Z-score method.\"\"\"\n",
    "    z_scores = np.abs((values - np.mean(values)) / np.std(values))\n",
    "    return z_scores > threshold\n",
    "\n",
    "def detect_anomalies_iqr(values, factor=1.5):\n",
    "    \"\"\"Detect anomalies using IQR method.\"\"\"\n",
    "    Q1 = np.percentile(values, 25)\n",
    "    Q3 = np.percentile(values, 75)\n",
    "    IQR = Q3 - Q1\n",
    "    lower_bound = Q1 - factor * IQR\n",
    "    upper_bound = Q3 + factor * IQR\n",
    "    return (values < lower_bound) | (values > upper_bound)\n",
    "\n",
    "def detect_anomalies_moving_avg(values, window=20, threshold=2):\n",
    "    \"\"\"Detect anomalies using moving average method.\"\"\"\n",
    "    moving_avg = pd.Series(values).rolling(window=window, center=True).mean()\n",
    "    moving_std = pd.Series(values).rolling(window=window, center=True).std()\n",
    "    deviation = np.abs(values - moving_avg) / moving_std\n",
    "    return deviation > threshold\n",
    "\n",
    "# Apply statistical methods\n",
    "df['anomaly_zscore'] = detect_anomalies_zscore(df['anomalous'])\n",
    "df['anomaly_iqr'] = detect_anomalies_iqr(df['anomalous'])\n",
    "df['anomaly_moving_avg'] = detect_anomalies_moving_avg(df['anomalous'])\n",
    "\n",
    "# Calculate performance metrics\n",
    "def calculate_metrics(true_anomalies, predicted_anomalies):\n",
    "    \"\"\"Calculate precision, recall, and F1-score.\"\"\"\n",
    "    tp = np.sum(true_anomalies & predicted_anomalies)\n",
    "    fp = np.sum(~true_anomalies & predicted_anomalies)\n",
    "    fn = np.sum(true_anomalies & ~predicted_anomalies)\n",
    "    \n",
    "    precision = tp / (tp + fp) if (tp + fp) > 0 else 0\n",
    "    recall = tp / (tp + fn) if (tp + fn) > 0 else 0\n",
    "    f1 = 2 * (precision * recall) / (precision + recall) if (precision + recall) > 0 else 0\n",
    "    \n",
    "    return precision, recall, f1\n",
    "\n",
    "# Evaluate statistical methods\n",
    "methods = ['zscore', 'iqr', 'moving_avg']\n",
    "results = {}\n",
    "\n",
    "for method in methods:\n",
    "    col_name = f'anomaly_{method}'\n",
    "    precision, recall, f1 = calculate_metrics(df['is_anomaly'], df[col_name])\n",
    "    results[method] = {'precision': precision, 'recall': recall, 'f1': f1}\n",
    "    print(f\"{method.upper()}: Precision={precision:.3f}, Recall={recall:.3f}, F1={f1:.3f}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 3. Machine Learning Anomaly Detection"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Prepare features for ML models\n",
    "def create_features(values, window=10):\n",
    "    \"\"\"Create features for anomaly detection.\"\"\"\n",
    "    features = []\n",
    "    \n",
    "    for i in range(window, len(values)):\n",
    "        # Statistical features\n",
    "        window_data = values[i-window:i]\n",
    "        feat = [\n",
    "            np.mean(window_data),\n",
    "            np.std(window_data),\n",
    "            np.min(window_data),\n",
    "            np.max(window_data),\n",
    "            np.percentile(window_data, 25),\n",
    "            np.percentile(window_data, 75),\n",
    "            values[i] - np.mean(window_data),  # deviation from window mean\n",
    "            (values[i] - values[i-1]) if i > 0 else 0,  # first difference\n",
    "        ]\n",
    "        features.append(feat)\n",
    "    \n",
    "    return np.array(features)\n",
    "\n",
    "# Create features\n",
    "window_size = 20\n",
    "X = create_features(df['anomalous'].values, window_size)\n",
    "y_true = df['is_anomaly'].values[window_size:]\n",
    "\n",
    "# Standardize features\n",
    "scaler = StandardScaler()\n",
    "X_scaled = scaler.fit_transform(X)\n",
    "\n",
    "print(f\"Feature matrix shape: {X_scaled.shape}\")\n",
    "print(f\"True anomalies in features: {np.sum(y_true)}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Isolation Forest\n",
    "iso_forest = IsolationForest(contamination=0.05, random_state=42)\n",
    "iso_predictions = iso_forest.fit_predict(X_scaled)\n",
    "iso_anomalies = iso_predictions == -1\n",
    "\n",
    "# Local Outlier Factor\n",
    "lof = LocalOutlierFactor(n_neighbors=20, contamination=0.05)\n",
    "lof_predictions = lof.fit_predict(X_scaled)\n",
    "lof_anomalies = lof_predictions == -1\n",
    "\n",
    "# Evaluate ML methods\n",
    "iso_precision, iso_recall, iso_f1 = calculate_metrics(y_true, iso_anomalies)\n",
    "lof_precision, lof_recall, lof_f1 = calculate_metrics(y_true, lof_anomalies)\n",
    "\n",
    "print(f\"Isolation Forest: Precision={iso_precision:.3f}, Recall={iso_recall:.3f}, F1={iso_f1:.3f}\")\n",
    "print(f\"LOF: Precision={lof_precision:.3f}, Recall={lof_recall:.3f}, F1={lof_f1:.3f}\")\n",
    "\n",
    "# Add results to dataframe\n",
    "df_ml = df.iloc[window_size:].copy()\n",
    "df_ml['anomaly_isolation_forest'] = iso_anomalies\n",
    "df_ml['anomaly_lof'] = lof_anomalies"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 4. LSTM Autoencoder Anomaly Detection"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Prepare data for LSTM autoencoder\n",
    "def create_sequences(data, seq_length):\n",
    "    \"\"\"Create sequences for LSTM training.\"\"\"\n",
    "    sequences = []\n",
    "    for i in range(len(data) - seq_length + 1):\n",
    "        sequences.append(data[i:i + seq_length])\n",
    "    return np.array(sequences)\n",
    "\n",
    "# Use only normal data for training (unsupervised)\n",
    "normal_data_only = df['normal'].values\n",
    "seq_length = 50\n",
    "\n",
    "# Normalize data\n",
    "data_mean = np.mean(normal_data_only)\n",
    "data_std = np.std(normal_data_only)\n",
    "normalized_normal = (normal_data_only - data_mean) / data_std\n",
    "normalized_anomalous = (df['anomalous'].values - data_mean) / data_std\n",
    "\n",
    "# Create sequences\n",
    "X_train = create_sequences(normalized_normal, seq_length)\n",
    "X_test = create_sequences(normalized_anomalous, seq_length)\n",
    "\n",
    "print(f\"Training sequences: {X_train.shape}\")\n",
    "print(f\"Test sequences: {X_test.shape}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Build LSTM autoencoder\n",
    "def build_lstm_autoencoder(seq_length, n_features=1):\n",
    "    \"\"\"Build LSTM autoencoder model.\"\"\"\n",
    "    # Encoder\n",
    "    input_layer = Input(shape=(seq_length, n_features))\n",
    "    encoded = LSTM(64, activation='relu', return_sequences=True)(input_layer)\n",
    "    encoded = LSTM(32, activation='relu', return_sequences=False)(encoded)\n",
    "    \n",
    "    # Decoder\n",
    "    decoded = RepeatVector(seq_length)(encoded)\n",
    "    decoded = LSTM(32, activation='relu', return_sequences=True)(decoded)\n",
    "    decoded = LSTM(64, activation='relu', return_sequences=True)(decoded)\n",
    "    decoded = TimeDistributed(Dense(n_features))(decoded)\n",
    "    \n",
    "    autoencoder = Model(input_layer, decoded)\n",
    "    autoencoder.compile(optimizer='adam', loss='mse')\n",
    "    \n",
    "    return autoencoder\n",
    "\n",
    "# Build and train model\n",
    "autoencoder = build_lstm_autoencoder(seq_length)\n",
    "print(\"Training LSTM autoencoder...\")\n",
    "\n",
    "# Reshape for LSTM (add feature dimension)\n",
    "X_train_reshaped = X_train.reshape(X_train.shape[0], X_train.shape[1], 1)\n",
    "X_test_reshaped = X_test.reshape(X_test.shape[0], X_test.shape[1], 1)\n",
    "\n",
    "# Train autoencoder\n",
    "history = autoencoder.fit(\n",
    "    X_train_reshaped, X_train_reshaped,\n",
    "    epochs=50,\n",
    "    batch_size=32,\n",
    "    validation_split=0.2,\n",
    "    verbose=0\n",
    ")\n",
    "\n",
    "print(\"✅ LSTM autoencoder training completed\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Use autoencoder for anomaly detection\n",
    "# Predict and calculate reconstruction error\n",
    "X_pred = autoencoder.predict(X_test_reshaped)\n",
    "reconstruction_errors = np.mean(np.square(X_test_reshaped - X_pred), axis=(1, 2))\n",
    "\n",
    "# Determine threshold (using percentile of training reconstruction errors)\n",
    "train_pred = autoencoder.predict(X_train_reshaped)\n",
    "train_errors = np.mean(np.square(X_train_reshaped - train_pred), axis=(1, 2))\n",
    "threshold = np.percentile(train_errors, 95)  # 95th percentile\n",
    "\n",
    "# Identify anomalies\n",
    "lstm_anomalies = reconstruction_errors > threshold\n",
    "\n",
    "# Map back to original indices\n",
    "y_true_lstm = df['is_anomaly'].values[seq_length-1:seq_length-1+len(lstm_anomalies)]\n",
    "\n",
    "# Evaluate LSTM autoencoder\n",
    "lstm_precision, lstm_recall, lstm_f1 = calculate_metrics(y_true_lstm, lstm_anomalies)\n",
    "print(f\"LSTM Autoencoder: Precision={lstm_precision:.3f}, Recall={lstm_recall:.3f}, F1={lstm_f1:.3f}\")\n",
    "print(f\"Threshold: {threshold:.4f}\")\n",
    "print(f\"Anomalies detected: {np.sum(lstm_anomalies)}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 5. Results Comparison and Visualization"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Compile all results\n",
    "all_results = {\n",
    "    'Z-Score': results['zscore'],\n",
    "    'IQR': results['iqr'],\n",
    "    'Moving Avg': results['moving_avg'],\n",
    "    'Isolation Forest': {'precision': iso_precision, 'recall': iso_recall, 'f1': iso_f1},\n",
    "    'LOF': {'precision': lof_precision, 'recall': lof_recall, 'f1': lof_f1},\n",
    "    'LSTM Autoencoder': {'precision': lstm_precision, 'recall': lstm_recall, 'f1': lstm_f1}\n",
    "}\n",
    "\n",
    "# Create comparison DataFrame\n",
    "comparison_df = pd.DataFrame(all_results).T\n",
    "print(\"🏆 Method Comparison:\")\n",
    "print(comparison_df.round(3))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Visualization of results\n",
    "fig, axes = plt.subplots(2, 2, figsize=(20, 12))\n",
    "\n",
    "# Performance comparison\n",
    "methods = list(all_results.keys())\n",
    "metrics = ['precision', 'recall', 'f1']\n",
    "colors = ['skyblue', 'lightgreen', 'salmon']\n",
    "\n",
    "x = np.arange(len(methods))\n",
    "width = 0.25\n",
    "\n",
    "for i, metric in enumerate(metrics):\n",
    "    values = [all_results[method][metric] for method in methods]\n",
    "    axes[0, 0].bar(x + i*width, values, width, label=metric.capitalize(), color=colors[i])\n",
    "\n",
    "axes[0, 0].set_xlabel('Methods')\n",
    "axes[0, 0].set_ylabel('Score')\n",
    "axes[0, 0].set_title('Anomaly Detection Performance Comparison')\n",
    "axes[0, 0].set_xticks(x + width)\n",
    "axes[0, 0].set_xticklabels(methods, rotation=45)\n",
    "axes[0, 0].legend()\n",
    "axes[0, 0].grid(True, alpha=0.3)\n",
    "\n",
    "# F1-Score comparison\n",
    "f1_scores = [all_results[method]['f1'] for method in methods]\n",
    "axes[0, 1].bar(methods, f1_scores, color='lightcoral')\n",
    "axes[0, 1].set_title('F1-Score Comparison')\n",
    "axes[0, 1].set_ylabel('F1-Score')\n",
    "axes[0, 1].tick_params(axis='x', rotation=45)\n",
    "axes[0, 1].grid(True, alpha=0.3)\n",
    "\n",
    "# LSTM reconstruction errors\n",
    "axes[1, 0].plot(reconstruction_errors, alpha=0.7, label='Reconstruction Error')\n",
    "axes[1, 0].axhline(y=threshold, color='red', linestyle='--', label=f'Threshold ({threshold:.4f})')\n",
    "axes[1, 0].scatter(np.where(lstm_anomalies)[0], reconstruction_errors[lstm_anomalies], \n",
    "                  color='red', s=30, alpha=0.8, label='Detected Anomalies')\n",
    "axes[1, 0].set_title('LSTM Autoencoder - Reconstruction Errors')\n",
    "axes[1, 0].set_xlabel('Time Steps')\n",
    "axes[1, 0].set_ylabel('Reconstruction Error')\n",
    "axes[1, 0].legend()\n",
    "axes[1, 0].grid(True, alpha=0.3)\n",
    "\n",
    "# Time series with all detected anomalies\n",
    "time_subset = df.iloc[100:300]  # Show a subset for clarity\n",
    "axes[1, 1].plot(time_subset.index, time_subset['anomalous'], alpha=0.7, label='Time Series')\n",
    "true_anomalies_subset = time_subset[time_subset['is_anomaly']]\n",
    "axes[1, 1].scatter(true_anomalies_subset.index, true_anomalies_subset['anomalous'], \n",
    "                  color='red', s=50, label='True Anomalies', marker='x')\n",
    "detected_subset = time_subset[time_subset['anomaly_zscore']]\n",
    "axes[1, 1].scatter(detected_subset.index, detected_subset['anomalous'], \n",
    "                  color='orange', s=30, alpha=0.7, label='Z-Score Detected', marker='o')\n",
    "axes[1, 1].set_title('Anomaly Detection Results (Subset)')\n",
    "axes[1, 1].set_xlabel('Time')\n",
    "axes[1, 1].set_ylabel('Value')\n",
    "axes[1, 1].legend()\n",
    "axes[1, 1].grid(True, alpha=0.3)\n",
    "\n",
    "plt.tight_layout()\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 6. Summary and Recommendations"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Generate summary report\n",
    "print(\"\\n\" + \"=\"*80)\n",
    "print(\"📋 ANOMALY DETECTION ANALYSIS SUMMARY\")\n",
    "print(\"=\"*80)\n",
    "\n",
    "print(f\"\\n📊 Dataset Statistics:\")\n",
    "print(f\"   Total data points: {len(df)}\")\n",
    "print(f\"   True anomalies: {np.sum(df['is_anomaly'])} ({np.mean(df['is_anomaly'])*100:.1f}%)\")\n",
    "print(f\"   Time range: {df.index.min().strftime('%Y-%m-%d')} to {df.index.max().strftime('%Y-%m-%d')}\")\n",
    "\n",
    "print(f\"\\n🏆 Best Performing Methods:\")\n",
    "best_f1 = max(f1_scores)\n",
    "best_method = methods[f1_scores.index(best_f1)]\n",
    "print(f\"   Best F1-Score: {best_method} ({best_f1:.3f})\")\n",
    "\n",
    "best_precision = max([all_results[method]['precision'] for method in methods])\n",
    "best_precision_method = [method for method in methods if all_results[method]['precision'] == best_precision][0]\n",
    "print(f\"   Best Precision: {best_precision_method} ({best_precision:.3f})\")\n",
    "\n",
    "best_recall = max([all_results[method]['recall'] for method in methods])\n",
    "best_recall_method = [method for method in methods if all_results[method]['recall'] == best_recall][0]\n",
    "print(f\"   Best Recall: {best_recall_method} ({best_recall:.3f})\")\n",
    "\n",
    "print(f\"\\n💡 Recommendations:\")\n",
    "if best_f1 > 0.7:\n",
    "    print(f\"   ✅ {best_method} shows excellent performance for this dataset\")\n",
    "elif best_f1 > 0.5:\n",
    "    print(f\"   ⚠️ {best_method} shows moderate performance - consider ensemble methods\")\n",
    "else:\n",
    "    print(f\"   ❌ All methods show poor performance - review data quality and parameters\")\n",
    "\n",
    "print(f\"\\n🔧 Method-Specific Insights:\")\n",
    "for method, result in all_results.items():\n",
    "    f1 = result['f1']\n",
    "    if f1 > 0.6:\n",
    "        print(f\"   ✅ {method}: High performance (F1={f1:.3f})\")\n",
    "    elif f1 > 0.3:\n",
    "        print(f\"   ⚠️ {method}: Moderate performance (F1={f1:.3f}) - tune parameters\")\n",
    "    else:\n",
    "        print(f\"   ❌ {method}: Poor performance (F1={f1:.3f}) - not suitable for this data\")\n",
    "\n",
    "print(f\"\\n📈 Improvement Suggestions:\")\n",
    "print(f\"   • Try ensemble methods combining multiple detectors\")\n",
    "print(f\"   • Adjust contamination rate based on domain knowledge\")\n",
    "print(f\"   • Use domain-specific features for better detection\")\n",
    "print(f\"   • Consider temporal patterns and seasonality\")\n",
    "print(f\"   • Validate results with domain experts\")\n",
    "\n",
    "print(\"\\n\" + \"=\"*80)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Next Steps\n",
    "\n",
    "This notebook demonstrated various anomaly detection techniques on TSIOT-generated synthetic data. Consider:\n",
    "\n",
    "1. **Parameter Tuning**: Optimize thresholds and parameters for each method\n",
    "2. **Ensemble Methods**: Combine multiple detectors for better performance\n",
    "3. **Real-time Detection**: Implement streaming anomaly detection\n",
    "4. **Domain Adaptation**: Customize methods for specific use cases\n",
    "5. **Validation**: Test on real-world data to ensure effectiveness\n",
    "\n",
    "For more examples, explore other notebooks in this directory or visit the [TSIOT documentation](../../docs/)."
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.0"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}